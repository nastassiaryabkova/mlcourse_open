{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Open Machine Learning Course\n",
    "<center>\n",
    "Author: Yury Kashnitsky, Data Scientist at Mail.Ru Group\n",
    "\n",
    "This material is subject to the terms and conditions of the license [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Free use is permitted for any non-comercial purpose with an obligatory indication of the names of the authors and of the source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Assignment #6. Part 1\n",
    "### <center> Beating benchmarks in \"Catch Me If You Can: Intruder Detection through Webpage Session Tracking\"\n",
    "    \n",
    "[Competition](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2). The task is to beat \"Assignment 6 baseline\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Additional libraries \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../data/websites_train_sessions.csv', index_col='session_id')\n",
    "test_df = pd.read_csv('../../data/websites_test_sessions.csv', index_col='session_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate target feature (AFTER SORTING!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train_df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's repeat old steps from Assignmet №4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>784.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2               time2  site3  \\\n",
       "session_id                                                                \n",
       "21669          56 2013-01-12 08:05:57   55.0 2013-01-12 08:05:57    NaN   \n",
       "54843          56 2013-01-12 08:37:23   55.0 2013-01-12 08:37:23   56.0   \n",
       "77292         946 2013-01-12 08:50:13  946.0 2013-01-12 08:50:14  951.0   \n",
       "\n",
       "                         time3  site4               time4  site5  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843      2013-01-12 09:07:07   55.0 2013-01-12 09:07:09    NaN   \n",
       "77292      2013-01-12 08:50:15  946.0 2013-01-12 08:50:15  946.0   \n",
       "\n",
       "                         time5  ...                 time6  site7  \\\n",
       "session_id                      ...                                \n",
       "21669                      NaT  ...                   NaT    NaN   \n",
       "54843                      NaT  ...                   NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  ...   2013-01-12 08:50:16  948.0   \n",
       "\n",
       "                         time7  site8               time8  site9  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843                      NaT    NaN                 NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  784.0 2013-01-12 08:50:16  949.0   \n",
       "\n",
       "                         time9 site10              time10 target  \n",
       "session_id                                                        \n",
       "21669                      NaT    NaN                 NaT      0  \n",
       "54843                      NaT    NaN                 NaT      0  \n",
       "77292      2013-01-12 08:50:17  946.0 2013-01-12 08:50:17      0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Switch time1, ..., time10 columns to datetime type\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "test_df[times] = test_df[times].apply(pd.to_datetime)\n",
    "\n",
    "# Sort the data by time\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "\n",
    "# Look at the first rows of the training set\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset contains the following features:\n",
    "\n",
    "- **site1** – id of the first visited website in the session\n",
    "- **time1** – visiting time for the first website in the session\n",
    "- ...\n",
    "- **site10** – id of the tenth visited website in the session\n",
    "- **time10** – visiting time for the tenth website in the session\n",
    "- **target** – target variable, value 1 for Alice's sessions, and 0 otherwise\n",
    "    \n",
    "User sessions are chosen in such a way that they are no longer than half an hour and/or contain more than ten websites i.e. a session is considered ended if either a user has visited ten websites or a session has lasted for more than thirty minutes.\n",
    "\n",
    "There are some empty values in the table, which means that these sessions contain less than ten websites. Replace empty values with 0, and change the columns' types to integer. Load the website's dictionary and see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Websites total: 48371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25075</th>\n",
       "      <td>www.abmecatronique.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>groups.live.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42436</th>\n",
       "      <td>majeureliguefootball.wordpress.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>cdt46.media.tourinsoft.eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>www.hdwallpapers.eu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     site\n",
       "25075              www.abmecatronique.com\n",
       "13997                     groups.live.com\n",
       "42436  majeureliguefootball.wordpress.com\n",
       "30911           cdt46.media.tourinsoft.eu\n",
       "8104                  www.hdwallpapers.eu"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change site1, ..., site10 columns type to integer and fill NA-values with zeros\n",
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df[sites] = train_df[sites].fillna(0).astype('int')\n",
    "test_df[sites] = test_df[sites].fillna(0).astype('int')\n",
    "\n",
    "# Load websites dictionary\n",
    "with open(r\"../../data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# Create dataframe for the dictionary\n",
    "sites_dict = pd.DataFrame(list(site_dict.keys()), index=list(site_dict.values()), columns=['site'])\n",
    "print(u'Websites total:', sites_dict.shape[0])\n",
    "sites_dict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check which websites in the training data set are the most visited. As you can see, they are Google services and a bioinformatics website (a website with 'zero'-index is our missed values, just ignore it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21     123776\n",
      "0      122730\n",
      "23      87619\n",
      "782     77055\n",
      "22      58258\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>www.google.fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>www.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>annotathon.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>apis.google.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                site\n",
       "21     www.google.fr\n",
       "0                NaN\n",
       "23    www.google.com\n",
       "782   annotathon.org\n",
       "22   apis.google.com"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top websites in the training data set\n",
    "top_sites = pd.Series(train_df[sites].fillna(0).values.flatten()\n",
    "                     ).value_counts().sort_values(ascending=False).head(5)\n",
    "print(top_sites)\n",
    "sites_dict.loc[top_sites.index.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77      1382\n",
      "80      1354\n",
      "76      1307\n",
      "29       897\n",
      "21       857\n",
      "81       609\n",
      "879      522\n",
      "22       522\n",
      "75       451\n",
      "82       447\n",
      "23       437\n",
      "35       381\n",
      "881      371\n",
      "37       293\n",
      "33       291\n",
      "3000     286\n",
      "733      274\n",
      "30       272\n",
      "78       236\n",
      "941      215\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>i1.ytimg.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>s.youtube.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>www.youtube.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>www.facebook.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>www.google.fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>r4---sn-gxo5uxg-jqbe.googlevideo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>r1---sn-gxo5uxg-jqbe.googlevideo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>apis.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>s.ytimg.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>r2---sn-gxo5uxg-jqbe.googlevideo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>www.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>s-static.ak.facebook.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>r3---sn-gxo5uxg-jqbe.googlevideo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>twitter.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>static.ak.facebook.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>vk.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>translate.google.fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>platform.twitter.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>yt3.ggpht.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>mts0.google.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      site\n",
       "77                            i1.ytimg.com\n",
       "80                           s.youtube.com\n",
       "76                         www.youtube.com\n",
       "29                        www.facebook.com\n",
       "21                           www.google.fr\n",
       "81    r4---sn-gxo5uxg-jqbe.googlevideo.com\n",
       "879   r1---sn-gxo5uxg-jqbe.googlevideo.com\n",
       "22                         apis.google.com\n",
       "75                             s.ytimg.com\n",
       "82    r2---sn-gxo5uxg-jqbe.googlevideo.com\n",
       "23                          www.google.com\n",
       "35                s-static.ak.facebook.com\n",
       "881   r3---sn-gxo5uxg-jqbe.googlevideo.com\n",
       "37                             twitter.com\n",
       "33                  static.ak.facebook.com\n",
       "3000                                vk.com\n",
       "733                    translate.google.fr\n",
       "30                    platform.twitter.com\n",
       "78                           yt3.ggpht.com\n",
       "941                        mts0.google.com"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top Alice's websites in the training data set\n",
    "a_df = train_df[train_df['target']==1]\n",
    "a_top_sites = pd.Series(a_df[sites].fillna(0).values.flatten()\n",
    "                     ).value_counts().sort_values(ascending=False).head(20)\n",
    "print(a_top_sites)\n",
    "sites_dict.loc[a_top_sites.index.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of websites does Alice visit the most? => videohostings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us look at the timestamps and try to characterize sessions by timeframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>1786.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target                 min                 max  seconds\n",
       "session_id                                                         \n",
       "21669            0 2013-01-12 08:05:57 2013-01-12 08:05:57      0.0\n",
       "54843            0 2013-01-12 08:37:23 2013-01-12 09:07:09   1786.0\n",
       "77292            0 2013-01-12 08:50:13 2013-01-12 08:50:17      4.0\n",
       "114021           0 2013-01-12 08:50:17 2013-01-12 08:50:20      3.0\n",
       "146670           0 2013-01-12 08:50:20 2013-01-12 08:50:22      2.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a separate dataframe where we will work with timestamps\n",
    "time_df = pd.DataFrame(index=train_df.index)\n",
    "time_df['target'] = train_df['target']\n",
    "\n",
    "# Find sessions' starting and ending\n",
    "time_df['min'] = train_df[times].min(axis=1)\n",
    "time_df['max'] = train_df[times].max(axis=1)\n",
    "\n",
    "# Calculate sessions' duration in seconds\n",
    "time_df['seconds'] = (time_df['max'] - time_df['min']) / np.timedelta64(1, 's')\n",
    "\n",
    "time_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional notes: \n",
    "\n",
    "- on average, Alice's session is shorter than other users'one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52.29647366129734, 139.28237232552215)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df[time_df['target'] == 1]['seconds'].mean(), time_df[time_df['target'] == 0]['seconds'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train our first model, we need to prepare the data. First, exclude the target variable from the training set. Both training and test sets now have the same number of columns, and we can aggregate them into a single dataframe. All transformations will therefore be performed simultaneously on both training and test data sets.\n",
    "\n",
    "On the one hand, this will lead to the fact that both data sets have one feature space (you don't have to worry that you forgot to transform a feature in some data sets). On the other hand, processing time will increase. For enormously large sets, it might be impossible to transform both data sets simultaneously, and you willhave to split your transformations into several stages across the train/test data set). For this dataset, we are going to perform all the transformations for the whole combined dataframe at once and will filter the appropriate part before training the model or making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# United dataframe of the initial data \n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n",
    "\n",
    "# Index to split the training and test data sets\n",
    "idx_split = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the basic model, we will use only the visited websites in the session (but will not take into account the timestamp features). The point behind this data selection is: *Alice has her favorite sites. The more often you see these sites in the session, the higher the probability that this is Alice and vice versa.*\n",
    "\n",
    "Now we'll prepare the data, taking only features `site1, site2, ... , site10` from the whole dataframe. Keep in mind that the missing values have been replaced with zero. Here is how the first rows of the dataframe should look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>784</td>\n",
       "      <td>949</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>949</td>\n",
       "      <td>948</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>948</td>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>952</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1  site2  site3  site4  site5  site6  site7  site8  site9  \\\n",
       "session_id                                                                  \n",
       "21669          56     55      0      0      0      0      0      0      0   \n",
       "54843          56     55     56     55      0      0      0      0      0   \n",
       "77292         946    946    951    946    946    945    948    784    949   \n",
       "114021        945    948    949    948    945    946    947    945    946   \n",
       "146670        947    950    948    947    950    952    946    951    946   \n",
       "\n",
       "            site10  \n",
       "session_id          \n",
       "21669            0  \n",
       "54843            0  \n",
       "77292          946  \n",
       "114021         946  \n",
       "146670         947  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe with indices of visited websites in session\n",
    "full_sites = full_df[sites]\n",
    "full_sites.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sessions are the sequences of website indices. This representation is inconvenient for linear methods. According to our hypothesis (Alice has favorite websites), we need to transform this dataframe so that each website has its corresponding feature (column) and that its value is equal to number of visits in the session. It can be accomplished with two lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sequence of indices\n",
    "sites_flatten = full_sites.values.flatten()\n",
    "\n",
    "# and the matrix we are looking for\n",
    "full_sites_sparse = csr_matrix(([1] * sites_flatten.shape[0],\n",
    "                                sites_flatten,\n",
    "                                range(0, sites_flatten.shape[0]  + 10, 10)))[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training the first model\n",
    "\n",
    "We have an algorithm and data for it. Let's build our first model using the [logistic regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) implementation from ` sklearn` with default parameters. We will use the first 90% of the data for training (sorted by time) and the remaining 10% for validation. Let's write a simple function that returns the quality of the model and then train our first classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_auc_lr_valid(X, y, C=1.0, seed=17, ratio = 0.9):\n",
    "    # Split the data into the training and validation sets\n",
    "    idx = int(round(X.shape[0] * ratio))\n",
    "    # Classifier training\n",
    "    lr = LogisticRegression(C=C, random_state=seed).fit(X[:idx, :], y[:idx])\n",
    "    # Prediction for validation set\n",
    "    y_pred = lr.predict_proba(X[idx:, :])[:, 1]\n",
    "    # Calculate the quality\n",
    "    score = roc_auc_score(y[idx:], y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.919524558715\n",
      "Wall time: 4.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Select the training set from the united dataframe (where we have the answers)\n",
    "X_train = full_sites_sparse[:idx_split, :]\n",
    "\n",
    "# Calculate metric on the validation set\n",
    "print(get_auc_lr_valid(X_train, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model achieved an accuracy of 0.91952 on the validation set. The will be the first baseline and starting point. To make a prediction on the test data set, ** we need to train the model again on the entire training dataset ** Up until now, our model used only part of the data for training; this will now increase its generalizing ability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for writing predictions to a file\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the whole training data set\n",
    "# Use random_state=17 for repeatability\n",
    "# Parameter C=1 by default, but here we set it explicitly\n",
    "lr = LogisticRegression(C=1.0, random_state=17).fit(X_train, y)\n",
    "\n",
    "# Make a prediction for test data set\n",
    "X_test = full_sites_sparse[idx_split:,:]\n",
    "y_test = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Write it to the file which could be submitted\n",
    "write_to_submission_file(y_test, 'baseline_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Improvement: New Features Engineering\n",
    "\n",
    "Now we are going to try to improve the quality of our model by adding new features to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataframe for new features\n",
    "full_new_feat = pd.DataFrame(index=full_df.index)\n",
    "\n",
    "# Add start_month feature\n",
    "full_new_feat['start_month'] = full_df['time1'].apply(lambda ts: 100 * ts.year + ts.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_new_feat['n_unique_sites'] = full_df[sites].nunique(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_month</th>\n",
       "      <th>n_unique_sites</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>morning</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82793</th>\n",
       "      <td>201410</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82794</th>\n",
       "      <td>201405</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82795</th>\n",
       "      <td>201405</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82796</th>\n",
       "      <td>201405</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82797</th>\n",
       "      <td>201411</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            start_month  n_unique_sites  start_hour  morning\n",
       "session_id                                                  \n",
       "82793            201410               4          18        0\n",
       "82794            201405               6          14        0\n",
       "82795            201405              10          11        1\n",
       "82796            201405               7          10        1\n",
       "82797            201411               2          10        1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_new_feat['start_hour'] = full_df['time1'].apply(lambda ts: ts.hour)\n",
    "full_new_feat['morning'] = full_df['time1'].apply(lambda ts: 1 if ts.hour <= 11 else 0)\n",
    "\n",
    "full_new_feat.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.959153723389\n"
     ]
    }
   ],
   "source": [
    "# Compose the training set\n",
    "tmp_scaled = StandardScaler().fit_transform(full_new_feat[['start_month', 'start_hour', \n",
    "                                                           'morning']])\n",
    "X_train = csr_matrix(hstack([full_sites_sparse[:idx_split,:], \n",
    "                             tmp_scaled[:idx_split,:]]))\n",
    "\n",
    "# Capture the quality with default parameters\n",
    "score_C_1 = get_auc_lr_valid(X_train, y)\n",
    "print(score_C_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Regularization Parameter Tuning\n",
    "\n",
    "We have introduced features that improve the quality of our model in comparison with the first baseline. Can we do even better? After we have formed the training and test sets, it almost always makes sense to search for the optimal hyperparameters - the parameters of the model that do not change during training.\n",
    "\n",
    "For example, in week 3, in decision trees, the depth of the tree is a hyperparameter, but the feature by which splitting occurs and its threshold is not. \n",
    "\n",
    "In the logistic regression we use, the weights of each feature are changing, and we find their optimal values during training; meanwhile, the regularization parameter remains constant. This is the hyperparameter that we are going to optimize now.\n",
    "\n",
    "We will try to beat this result by optimizing the regularization parameter. We will take a list of possible values of $C$ and calculate the quality metric on the validation set for each of $C$-values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# List of possible C-values\n",
    "Cs = np.logspace(-3, 1, 10)\n",
    "\n",
    "scores = []\n",
    "    \n",
    "for C in Cs:\n",
    "    scores.append(get_auc_lr_valid(X_train, y, C=C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the graph of the quality metric (AUC-ROC) versus the value of the regularization parameter. The value of quality metric corresponding to the default value of C=1 is represented by a horizontal dotted line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEaCAYAAADg2nttAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPydiywo1DLQQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x157da19fba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Cs, scores, 'ro-')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('AUC-ROC')\n",
    "plt.title('Regularization Parameter Tuning')\n",
    "# horizontal line -- model quality with default C value\n",
    "plt.axhline(y=score_C_1, linewidth=.5, color = 'b', linestyle='dashed') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1668100537200059"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_opt = Cs[scores.index(max(scores))]\n",
    "C_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using the optimal regularization parameter we found (0.92784 on the public leaderboard on Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.961212510688\n"
     ]
    }
   ],
   "source": [
    "# Prepare the training and test data\n",
    "tmp_scaled = StandardScaler().fit_transform(full_new_feat[['start_month', 'start_hour', 'morning']])\n",
    "X_train = csr_matrix(hstack([full_sites_sparse[:idx_split,:], \n",
    "                             tmp_scaled[:idx_split,:]]))\n",
    "X_test = csr_matrix(hstack([full_sites_sparse[idx_split:,:], \n",
    "                            tmp_scaled[idx_split:,:]]))\n",
    "\n",
    "# Train the model on the whole training data set using optimal regularization parameter\n",
    "lr = LogisticRegression(C=C_opt, random_state=17).fit(X_train, y)\n",
    "\n",
    "# Make a prediction for the test set\n",
    "y_test = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Capture the quality with optimized parameters\n",
    "score_C_opt = get_auc_lr_valid(X_train, y, C=C_opt)\n",
    "print(score_C_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write it to the submission file\n",
    "write_to_submission_file(y_test, 'baseline_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do new steps for Assignmet №6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Tf-Idf features based on sites. You can use `ngram_range`=(1, 3) and `max_features`=100000 or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_new_feat['all_sites'] = \\\n",
    "full_sites['site1'].map(str) + ' ' + \\\n",
    "full_sites['site2'].map(str) + ' ' + \\\n",
    "full_sites['site3'].map(str) + ' ' + \\\n",
    "full_sites['site4'].map(str) + ' ' + \\\n",
    "full_sites['site5'].map(str) + ' ' + \\\n",
    "full_sites['site6'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.960998449947\n"
     ]
    }
   ],
   "source": [
    "bag_of_sites = vectorizer.fit_transform(full_new_feat['all_sites'])\n",
    "\n",
    "# Prepare the training and test data\n",
    "tmp_scaled = StandardScaler().fit_transform(full_new_feat[['start_month', 'start_hour', 'morning']])\n",
    "X_train = csr_matrix(hstack([full_sites_sparse[:idx_split,:],  bag_of_sites[:idx_split,:], \n",
    "                             tmp_scaled[:idx_split,:]]))\n",
    "X_test = csr_matrix(hstack([full_sites_sparse[idx_split:,:],  bag_of_sites[idx_split:,:], \n",
    "                            tmp_scaled[idx_split:,:]]))\n",
    "\n",
    "# Train the model on the whole training data set using optimal regularization parameter\n",
    "lr = LogisticRegression(C=C_opt, random_state=17).fit(X_train, y)\n",
    "\n",
    "# Make a prediction for the test set\n",
    "y_test = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Capture the quality with optimized parameters\n",
    "score_C_opt = get_auc_lr_valid(X_train, y, C=C_opt)\n",
    "print(score_C_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that score decreases. Let's find new C_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# List of possible C-values\n",
    "Cs = np.logspace(-3, 1, 10)\n",
    "\n",
    "scores = []\n",
    "    \n",
    "for C in Cs:\n",
    "    scores.append(get_auc_lr_valid(X_train, y, C=C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059948425031894091"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_opt = Cs[scores.index(max(scores))]\n",
    "C_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.961103366883\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the whole training data set using optimal regularization parameter\n",
    "lr = LogisticRegression(C=C_opt, random_state=17).fit(X_train, y)\n",
    "\n",
    "# Capture the quality with optimized parameters\n",
    "score_C_opt = get_auc_lr_valid(X_train, y, C=C_opt)\n",
    "print(score_C_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still decreased. Let's do  Tf–idf term weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "tfidf = transformer.fit_transform(bag_of_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.961467104087\n"
     ]
    }
   ],
   "source": [
    "# Prepare the training and test data\n",
    "tmp_scaled = StandardScaler().fit_transform(full_new_feat[['start_month', 'start_hour', 'morning']])\n",
    "X_train = csr_matrix(hstack([full_sites_sparse[:idx_split,:],  tfidf[:idx_split,:], \n",
    "                             tmp_scaled[:idx_split,:]]))\n",
    "X_test = csr_matrix(hstack([full_sites_sparse[idx_split:,:],  tfidf[idx_split:,:], \n",
    "                            tmp_scaled[idx_split:,:]]))\n",
    "\n",
    "# Train the model on the whole training data set using optimal regularization parameter\n",
    "lr = LogisticRegression(C=C_opt, random_state=17).fit(X_train, y)\n",
    "\n",
    "# Capture the quality with optimized parameters\n",
    "score_C_opt = get_auc_lr_valid(X_train, y, C=C_opt)\n",
    "print(score_C_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also let's find new C_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 54.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# List of possible C-values\n",
    "Cs = np.logspace(-3, 1, 10)\n",
    "scores = []\n",
    "    \n",
    "for C in Cs:\n",
    "    scores.append(get_auc_lr_valid(X_train, y, C=C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1668100537200059"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_opt = Cs[scores.index(max(scores))]\n",
    "C_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.962115022777\n"
     ]
    }
   ],
   "source": [
    "# Prepare the training and test data\n",
    "tmp_scaled = StandardScaler().fit_transform(full_new_feat[['start_month', 'start_hour', 'morning']])\n",
    "X_train = csr_matrix(hstack([full_sites_sparse[:idx_split,:],  tfidf[:idx_split,:], \n",
    "                             tmp_scaled[:idx_split,:]]))\n",
    "X_test = csr_matrix(hstack([full_sites_sparse[idx_split:,:],  tfidf[idx_split:,:], \n",
    "                            tmp_scaled[idx_split:,:]]))\n",
    "\n",
    "# Train the model on the whole training data set using optimal regularization parameter\n",
    "lr = LogisticRegression(C=C_opt, random_state=17).fit(X_train, y)\n",
    "\n",
    "# Capture the quality with optimized parameters\n",
    "score_C_opt = get_auc_lr_valid(X_train, y, C=C_opt)\n",
    "print(score_C_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a prediction for the test set\n",
    "y_test = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Write it to the submission file\n",
    "write_to_submission_file(y_test, 'assignment6_alice_submission_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add features based on the session start time: hour, whether it's morning, day or night and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale these features and combine them with Tf-Idf based on sites (you'll need `scipy.sparse.hstack`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform cross-validation with logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction for the test set and form a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = # You code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_submission_file(test_pred, \"assignment6_alice_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
